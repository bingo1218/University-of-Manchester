---
title: "assignment 2"
author: "zhb"
date: "15/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<span style = "font-family: Times New Roman; font-size: 1.5em; color: black"> Hi, Dr. Andrew, this is my work of **assignment 2**, hope you like it~ </span>

In this assignment, I am going to working on these 3 dataset, conducting including wrangling data, visualising the data, constructing different ANOVA model, and comparing the relationship between ANOVA and linear model.  

### Load all Packages

First, I'm going to load all the packages that should be used in the three questions, having already used the `install.packages` function directly in the console, e.g., `install.packages("tidyverse")`. 

Now we need to add these packages into our environment with function `library()`(e.g., `library(tidyverse)`). The main packages include:

- `tidyverse`: a collection of R packages using widely in data science. In the dataset, we specifically use ggplot2, dplyr and purrr.
  - `ggplot`: used to visualised the data
  - `dplyr`: includes `select`, `mutate`, `filter`, `summarise` and `arrange`. 
  - `purrr`: used to exclude extreme value (by assign function for each rows). 
- `afex`: provides a set of functions that make calculating ANOVAs easy.
- `emmeans`: is enormously useful for folks wanting to do post hoc comparisons among groups after fitting a model.
    

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(afex)
library(emmeans)
library(knitr)
library(ggpubr)
library(ggridges)
```

### Qestion 1 

#### Summary of the experiment

The dataset that we are going to process are the results from an experiment of between-subjects design with ninety-six participants randomly assigned into two groups, which one group is presented to normally words and the other is exposed to degraded words, comparing the the relationship between visual quality and response time of words. There are 3 steps to cope with this dataset: 1. Data Wrangling; 2. Data summary; 3. Data Visualization; 4. Statistical Analysis; 5. Results output

#### Data Wrangling

##### read in data
Now, we will read in the experimental data that we are going to analyses as a variable in our environment. 

The data comprises 96 rows with each subjects' ID number, condition of words assigned and response time of subjects. 

```{r}
Q1 <- read_csv("assignment_2_dataset_1.csv")
```

##### Understanding our data

As the tibble is one of the features of the tidyverse, we use the `as_tibble` default to change the type of the data to make sure our dataset is in tibble format.

```{r}
as_tibble(Q1)
```


Then, Using the function `head()` and `str()`, we get a basic understanding of our data's frame. 

- With `head()`, we could see the name, type and first 6 rows of the data, variable "condition" belongs to "chr", which means character variable. And the other two is "dbl", which means "double".

- with `str()`, we could see more details, including the number of each variables, and the structure of this dataset.

```{r}
head(Q1)
str(Q1)
```
##### Change the Data into Suitable Format

As we have an understanding about our data, now we can start to manipulate it. The first step is placing it into a appropriate format that could be recognized by different functions we might want to use later with `tidyverse` packages.

We have known our data is in a long format (which is correct, because we could see the one observation (each participant in its condition) is in just one column). However, as I described above, the type of condition is *chr*, but we want a factor here corresponding to our experimental design.

So, first, we use `mutate()` to change the class of the **condition** from *character* (chr)  to *factor* (fac).

Then, we change the Name of the Factors to present our experiment more clearly.

With **condition_a** and **condition_b**, we have no idea what are them except there are 2 conditions. So, we want to mutate the names of the **condition** to **Normal** (normally displayed) and **Degrade** (degraded displayed).

Here, we use :
- `<-` (a function to assign a value to a data) to cover the original **Q1** with class-changed condition. 
- the mark `%>%`, called `pipe`. The `pipe` is used to ensure information is passed with code through different lines.
- `mutate()` could replace variables and preserves existing ones. 
- `recode()` could switch the values based their name or position.

```{r}
Q1_tided <- Q1 %>%
  mutate(condition = factor(condition)) %>%
  rename(RT = response_time) %>%
  mutate(condition = recode(condition,
                            "condition_a" = "Normal",
                            "condition_b" = "Degrade"))
```

##### Filter the data

To exclude extreme value in the data (extreme value might affect our next statistical analysing, and might not satisfy the requirements of statistics). It might because the distraction of the participants.

We use map function in `purrr` packages (part of `tidyverse`).
- `purrr`:
  - `map`: allow you to replace many for loops with code that is both more succinct and easier to read.
- `append()`: allow you ti add elements to a vector (combine two to one).
- `filter()`: part of `dply`, retaining all rows that satisfy your requirements. Here, we set the threshold that the response time should be smaller than mean Â± 3 Standard deviation (of specific condition).
- `select()`: keeps only the variables you choose.
- `unlist()`: to change a *list* to a vector, with `use.names = False` to drop the name information
- `is.na()`: returns logical value showing if your value is *NA* or not, together with filter could drop the case with *NA*.

```{r}
Normal_fil <- Q1_tided %>%
  filter(condition == "Normal") %>%
  select(RT) %>% 
  map(function(x) ifelse(((x-mean(x))/sd(x)) <= 3, x, NA))

Degrade_fil <- Q1_tided %>%
  filter(condition == "Degrade") %>%
  select(RT) %>% 
  map(function(x) ifelse(((x-mean(x))/sd(x)) <= 3, x, NA))

Q1_fil <- Q1_tided
Q1_fil$RT <- append(unlist(Normal_fil, use.names = FALSE), unlist(Degrade_fil, use.names = FALSE))
Q1_fil%>% filter(!is.na(RT))
```

Finally, let's view our data again to see what happend to our original data and is everything correct.

```{r}
Q1_fil
```
#### Data Profile

To show the distribution, the representative value and other basic information of the dataset, we summary the data. For example, presenting the mean reaction, the standard deviance and the sample size of Reaction Time in two conditions.

Here, we use `summarise()` in `dplyr` packages to calculate these statistical variables. 

To do this, first we use `group_by` function to divide our data into two conditions (groups), so then the `summarise` could return to the summaries in two different conditions.

To get a better understanding with our data, we calculate:
- mean: the average of the values
- sd: standard deviance
- se: standard error
- median: the middle number in a sorted, ascending or descending
- max/min: the max and minimum value in a serious of data
- quantile(25% and 75%): three/one quarters of the way up this rank order
- variance: is the expectation of the squared deviation of a random variable from its population mean or sample mean
- sample size: the number of observations

```{r}
Q1_summarise <- Q1_fil %>%
  group_by(condition) %>%
  summarise(mean_RT = mean(RT),
            sd_RT = sd(RT),
            se = sd(RT) / sqrt(length(n)),
            median_RT = median(RT),
            max_RT = max(RT),
            min_RT = min(RT),
            quantile_RT25 = quantile(RT, 0.25), 
            quantile_RT75 = quantile(RT, 0.75),
            var_RT = var(RT),
            number = n())
```

Then, we use kable() function in knitr packages to draw a more formal table that could both show this information to our audience and also put in the future potential paper. 

- Considering the unit of **response time** is *ms*, we drop all the decimals with `digits = 0`.
- `caption` to give a title to this table
- `col.names` to rename the name of columns in the table.
- `format.args` to cancel the scientific notation, and add *,* to represent *thousands*; and align left the characters in the table with `align = "lllllll"`

```{r}
knitr::kable(
  Q1_summarise, 
  caption = "Profile of reaction time (RT) in two conditions", col.names = c('condition', 'Mean(ms)', 'SD (ms)', 'SE (ms)', 'median (ms)', 'max (ms)', 'min (ms)', '25% quantile (ms)', '75% quantile (ms)', 'variance (ms)', 'N'), digits = 0, format.args = list(big.mark = ",",
  scientific = FALSE), align = "lllllllllll")
```

#### data visualization

Before formal statistical analysis, we also need make it visible to help us have a better intuitive understanding about our data. It could inspire us to determine which kind of statistic should be used.

Here, we use density plot and scatter plot.

##### plot 1 - density plot

It is necessary to see the distribution of the data and the density curve is the intuitive and convenient way for us to know it.

- `geom_density_ridges`: used to generate the density(distribution) of the data.

- `guides`: used to set the properties of legends. 

- `them`: combined with `axis.text.x` to set the properties of text in x axis.

```{r, message = FALSE}
plot1_1 <- Q1_fil %>%
  ggplot(aes(x = RT, y = fct_reorder(condition, .fun = mean, RT))) +
  geom_density_ridges(height = .5, aes(fill = condition)) +
  theme_minimal() +
  theme(text = element_text(size = 13)) +
  guides(fill = 'none') + 
  labs(x = "The Reaction Time (ms)",
       y = "Density")
plot1_1
```




#### Statistical Analysis

##### Build Analysis of variance model
Let's first build an ANOVA model, and use summary() and emmeans() to conduct the post-hoc analysis.

```{r}
model1 <- aov_4(RT ~ condition + (1 | participant), data = Q1_fil)

sum1 <- summary(model1)

emm1 <- emmeans(model1, pairwise ~ condition)
```

Alternatively, when comparing the difference of two groups, it's more common to use T-test. Here, we also use t-test to make the comparing.

```{r}

```


#### Add P-values and Significance Levels to ggplots

After get the p-value of the ANOVA, now we could draw new pictures with significance for make our results of analysis more clearly and preparing for our potential publication.

We could add the significance manually with `geom_signif()` based on previous results. Especially for barplot, we cannot automatically and directly compare the difference between groups.

##### plot2 - histogram plot

```{r}
plot1_2 <- Q1_fil %>%
  group_by(condition) %>%
  summarise(mean_RT = mean(RT), sd_RT = sd(RT)) %>%
  ggplot(aes(x = condition, y = mean_RT)) +
  geom_bar(aes(fill = condition),
           stat="identity", 
           alpha = 0.7,
           color ="black", 
           width = 0.5) + 
  geom_text(aes(label = round(mean_RT, 2)), vjust = -1.5) +
  geom_errorbar(aes(ymin = mean_RT - sd_RT, 
                    ymax = mean_RT + sd_RT), 
                width = 0.25, 
                size = 1) +
  geom_signif(comparisons = list(c("Normal", "Degrade")), 
              annotations="***",
              y_position = 1300, tip_length = 0, vjust=0.4)+ 
  scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +
  scale_x_discrete(limits = rev) + 
  labs(x = "condition",
       y = "Response Time (ms)",
       title = "The mean of response time in two conditions") +
  theme_classic() +
  scale_fill_brewer(palette = "Set1")

plot1_2
```

##### plot 3 - scatter plot with volin and boxplot

Another way to add the p-value of the comparing is add `stat_compare_means` directly (from  `ggpubr` package), which is a easier way than above.

```{r}
plot1_3 <- Q1_fil %>%
  ggplot(aes(x = condition, y = RT, colour = condition)) +
  geom_violin(aes(fill = condition), 
              trim = FALSE, 
              width = 1, 
              alpha = 0.4) +
  geom_jitter(shape = 21,
              width = .2, 
              alpha = 2, 
              size = 2) + 
  geom_boxplot(alpha = .5) + 
  scale_fill_brewer(palette = "Set1") +
  guides(colour = 'none') + 
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 0, vjust = 5, hjust = .5)) +
  labs(title = "Response Time in Different Conditions",
       x = "condtion",
       y = "Response Time (ms)") +
  stat_compare_means(method = "anova")

plot1_3
#è¿éè¿éè¦å®åï¼ä½¿ç¨æ´å¤åæ°
```

```{r}

```

### Qestion 2

#### Data Wangling 

##### reading in data

```{r}
Q2 <- read_csv("assignment_2_dataset_2.csv")
as_tibble(Q2)
head(Q2)
str(Q2)
```

```{r}
Q2_tided <- Q2 %>%
  mutate(condition = factor(condition)) %>%
  rename(RT = response_time) %>%
  mutate(condition = recode(condition,
                            "condition_a" = "Normal",
                            "condition_b" = "Degrade"))
```

```{r}
Normal_fil2 <- Q2_tided %>%
  filter(condition == "Normal") %>%
  select(RT) %>% 
  map(function(x) ifelse(((x-mean(x))/sd(x)) <= 3, x, NA))

Degrade_fil2 <- Q2_tided %>%
  filter(condition == "Degrade") %>%
  select(RT) %>% 
  map(function(x) ifelse(((x-mean(x))/sd(x)) <= 3, x, NA))

Q2_fil <- Q2_tided
Q2_fil$RT <- append(as.numeric(unlist(Normal_fil2)), as.numeric(unlist(Degrade_fil2)))
Q2_fil%>% filter(!is.na(RT))
```
### Summarising our Data

```{r}

```

### Visualising our data

```{r}

```

### builing our ANOVA model

```{r}
model2_1 <- aov_4(RT ~ condition + caffeine + (1 | participant), data = Q2_fil, na.rm = TRUE, factorize = FALSE)

anova(model2_1)

emmeans(model_2, pairwise ~ condition)
```

# Regression model

contrast
we get the formula: RT = 998.564 + 12.791 * condition + 2.469 * caffeine
```{r}
contrasts(Q2_fil$condition)
model2_lm1 <- lm(RT ~ condition + caffeine, data = Q2_fil)
model2_lm1
mean(Q2_fil$caffeine)
```




```{r}
model2_2 <- aov_4(RT ~ condition * caffeine + (1 | participant), data = Q2_fil, na.rm = TRUE, factorize = FALSE)

summary(model2_2)
emm1 = emmeans(model2_2, pairwise ~ condition*caffeine)
emm1$emmeans
emm1$contrasts
```

